{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab5 Final assignment: putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final assignment is an individual assignment in which you put things together. You can earn 10 points when you carry out the basic tasks and discuss the results poperly.\n",
    "\n",
    "   1. **Train a BoW SVM Ekman emotion classifier combining all MELD and Tweet data** [3 POINTS]\n",
    "       1. Load the train, test and development data from MELD and WASSA\n",
    "       2. Discuss the statistics on the training data for the Ekman emotions\n",
    "       3. Create a BoW vector representation and train an SVM classifier\n",
    "       4. Save the classifier to disk\n",
    "   2. **Classify the turns from the Eliza conversation with emotion classifiers** [2 POINT]\n",
    "       1. load the annotated conversation from disk in this notebook as a Pandas dataframe (see below)\n",
    "       2. Apply the following emotion classifiers to your conversation:\n",
    "           1. BoW SVM classifier trained on the data from MELD and Wassa Tweets (see 2. above)\n",
    "           2. BERT finetuned with GO_emotions, where GO emotions are mapped to Ekman emotions (given in this notebook as shown below)\n",
    "   3. **Evaluate the classifiers against your gold annotations** [2 POINT]\n",
    "       1. Create a classification report and confusion matrix. Only evaluate the human input and ignore the Eliza prompts!\n",
    "       2. Discuss the result:\n",
    "           1. report on performance similarities and differences, \n",
    "           2. formulate what you expected from each model in terms of recall and precision and whether this is confirmed or falsified by the results \n",
    "           3. try to explain what did NOT meet your expectations\n",
    "   4. **Formulate what could be done to improve the automatic classification** [2 POINT]\n",
    "       1. How can you improve the classifiers by:\n",
    "           1. adapting training data, \n",
    "           2. processing the training data differently\n",
    "       2. Reflect on using different emotion labels: Ekman or Go.\n",
    "\n",
    "For the assignment, you need to load the conversations from the students with Eliza, which is provided as a separate CSV file.\n",
    "\n",
    "Below, we show how you can apply the BERT classifier finetuned with GO emotions to the conversations and add the result to the pandas dataframe. We also show how the GO emotions are mapped to Ekman emotions and sentiment values. This is an example how you can also proceed to you get the results for the other classifiers.\n",
    "\n",
    "If for some reason, you are not able to load the BERT-GO transformer model in your computer and cannot run it do the following:\n",
    "\n",
    "   1. Send me your conversation with the annotations saved in CSV\n",
    "   2. I will apply the transformer model for you and send back the CSV with the GO annotations\n",
    "   3. Load the CSV with the GO anotations and proceed from there\n",
    "\n",
    "After applying the BERT-GO classifier to your conversation, you will also apply a Bag-of-Word SVM classifier to your conversation. For this, you should build a BoW SVM classfier in a separate notebook (use **lab5.meld-tweet-bow-svm-emotion-classifier.ipynb**) which combines the MELD and Tweet data into a single set of training data. Note that you can also include the test and development data for training since we are applying the model to your conversation and not to the MELD and Wassa tests. \n",
    "\n",
    "Make a statistical analysis of the training data (you need for understabding the results) and save the classifier to disk so that you can use it here in this notebook. The notebook **lab5.meld-tweet-bow-svm-emotion-classifier.ipynb** can be used as a guide for building the classifier. Load the BoW SVM classifier that you built in this notebook from disk and apply it to the conversation. Add the result to the Pandas dataframe of the conversation as well. Once the pandas frame is complete with the annotations from all the classifiers, make sure you save it to disk as an XLS or CSV file to not loose anything!!!!\n",
    "\n",
    "For the evaluation of the classifiers, you need to extract the gold labels and the classifier labels for each classifcation model separately. When extracting the gold and system labels for the test, you should **ONLY(!!)** use the labels for the human responses and skip Eliza's responses. We provided a function in **lab5_util.py** to do this. \n",
    "\n",
    "Once you have extracted the gold labels and the system labels for the human responses (check if they have the same length and are in the right order), you can do the evaluation. With the **sklearn** functions you can generate a classification report and a confusion matrix (you can use **seaborn** to make the image nicer).\n",
    "\n",
    "When you report the results, it makes sense to combine these in a single table. So instead of having separate classification report tables, try to combine these in a single table so that you can easly compare them, as is shown in the following examples. Obviously, the confusion matrixes cannot be combined. You can add these to the appendix of the report on a single page for comparison.\n",
    "\n",
    "## Dummy example of an overview of EKMAN results\n",
    "\n",
    "![Ekman classification of human responses in a conversation](ekman-results.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment should be submitted individually on CANVAS as a zip file and include the following:\n",
    "\n",
    "   1. The notebook to create a BoW-SVM combining MELD and Tweets for Ekman classification: **lab5.meld-tweet-bow-svm-emotion-classifier.ipynb**\n",
    "   2. The current notebook **lab5.final_assignment.ipynb**\n",
    "   3. A CSV file containing the conversation with all the gold and classifier outputs (use clear column names)\n",
    "   4. A PDF report of max 5 pages:\n",
    "       1. Section 1: what you have done and why: be explicit about changes you made e.g. to Eliza or training on MELD+Tweets\n",
    "       2. Section 2: report on the Ekman classification results. Use a single table for recall, precision and f-score and put confusion matrixes in the appendix.\n",
    "       4. Section 3:a discussion on the results and how to improve the classifiers\n",
    "\n",
    "Use the notebooks that are given as a guide with the code and the output. You should NOT discuss the results in the notebooks but in the report. Use the notebooks to run the experiments and get the results. Include the tables and figures in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Loading the conversation saved on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the notebook **eliza-chat.ipynb**, you should create a conversation with Eliza, annotate the conversation with Ekman labels and save it to disk as a CSV file. You should load the saved CSV file here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello Piek. How are you feeling today?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I am sad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you feel about being sad?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How do you feel when you say that?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                               utterance speaker  \\\n",
       "0             0           0  Hello Piek. How are you feeling today?   Eliza   \n",
       "1             1           1                                I am sad    Piek   \n",
       "2             2           2        How do you feel about being sad?   Eliza   \n",
       "3             3           3                                     Bad    Piek   \n",
       "4             4           4      How do you feel when you say that?   Eliza   \n",
       "\n",
       "   turn_id     Gold  \n",
       "0        1  neutral  \n",
       "1        1  sadness  \n",
       "2        1  neutral  \n",
       "3        1  sadness  \n",
       "4        1  neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'my_emotional_conversation.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab5_util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CODE TO GET THE TEST TEXTS AND LABELS\n",
    "test_instances =df['utterance']\n",
    "test_labels = df['Gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 10\n"
     ]
    }
   ],
   "source": [
    "# THE CODE TO LIMIT THE TEST LABELS TO THE HUMAN TEST LABELS\n",
    "human_test_labels = util.remove_eliza_labels(df, test_labels)\n",
    "print(len(test_labels), len(human_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. BERT Finetuned for emotion detection with GO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the language model BERT that is finetuned for emotion detection using the *go_emotions* data set. Go_emotions has 28 nuanced emotion labels including neutral, so many more than the basic Ekman emotion that we have seen before. \n",
    "\n",
    "We will define a *sentiment-analysis* pipeline and load the BERT model that was finetuned to classify sentences with the 28 GO_EMOTION labels. It will return a score for all the labels when we set the parameter *return_all_scores* to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE BERT-BASE-GO-EMOTION transformer model and create a pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\" \n",
    "emotion_pipeline = pipeline('sentiment-analysis', \n",
    "                    model=model_name, return_all_scores=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created an instance *emotion* of a transformer pipeline in analogy of an sentiment analysis classification task that we can apply to any utterance. The pipeline will use the tokenizer of the finetuned model and feed the sentence representation to the classifier as a sequence of contextualized token representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Applying emotion classification to Eliza conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, you will apply the GO_EMOTION classifier *emotion* to the conversation loaded in a Pandas frame. You will also map the GO_EMOTIONS to the 6 basic Ekman emotion and to neutral as well as to sentiment values. For the mappings, we defined a few simple utility functions in **lab5_util.py** . We also define a sort function to list the emotions from the highest score down. You first need to import these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "\n",
    "go_sentiment_emotions = []\n",
    "go_sentiment_scores = []\n",
    "go_ekman_emotions = []\n",
    "go_ekman_scores = []\n",
    "go_emotions = []\n",
    "go_scores = []\n",
    "\n",
    "for index, utterance in enumerate(df['utterance']):\n",
    "    emotion_labels = emotion_pipeline(utterance)\n",
    "    sorted_emotion_labels = util.sort_predictions(emotion_labels[0])\n",
    "    go_emotions.append(sorted_emotion_labels[0]['label'])\n",
    "    go_scores.append(sorted_emotion_labels[0]['score'])\n",
    "\n",
    "    ekman_labels = util.get_averaged_mapped_scores_by_threshold(util.ekman_map, emotion_labels, threshold)\n",
    "    if ekman_labels:\n",
    "        go_ekman_emotions.append(ekman_labels[0]['label'])\n",
    "        go_ekman_scores.append(ekman_labels[0]['score'])\n",
    "    else:\n",
    "        #### none of the labels scored above the threshold\n",
    "        go_ekman_emotions.append('None')\n",
    "        go_ekman_scores.append(0)\n",
    "        \n",
    "\n",
    "    sentiment_labels = util.get_averaged_mapped_scores_by_threshold(util.sentiment_map, emotion_labels, threshold)\n",
    "    if sentiment_labels:\n",
    "        go_sentiment_emotions.append(sentiment_labels[0]['label'])\n",
    "        go_sentiment_scores.append(sentiment_labels[0]['score'])\n",
    "    else:\n",
    "        #### none of the labels scored above the threshold\n",
    "        go_sentiment_emotions.append('None')\n",
    "        go_sentiment_scores.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adding the output to the Pandas frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collected the GO output in separate lists for each utterance. You can now add the output to the pandas frame as separate columns, assuming that the values correspond to the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Go_Sentiment</th>\n",
       "      <th>Go_SentimentScore</th>\n",
       "      <th>Go_Ekman</th>\n",
       "      <th>Go_EkmanScore</th>\n",
       "      <th>Go</th>\n",
       "      <th>GoScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello Piek. How are you feeling today?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.237066</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.287125</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>0.330824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I am sad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.843814</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.843814</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.843814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you feel about being sad?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.344749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.107874</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.200429</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.200429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How do you feel when you say that?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.339241</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0.339241</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>0.585612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                               utterance speaker  \\\n",
       "0             0           0  Hello Piek. How are you feeling today?   Eliza   \n",
       "1             1           1                                I am sad    Piek   \n",
       "2             2           2        How do you feel about being sad?   Eliza   \n",
       "3             3           3                                     Bad    Piek   \n",
       "4             4           4      How do you feel when you say that?   Eliza   \n",
       "\n",
       "   turn_id     Gold Go_Sentiment  Go_SentimentScore  Go_Ekman  Go_EkmanScore  \\\n",
       "0        1  neutral    ambiguous           0.237066   neutral       0.287125   \n",
       "1        1  sadness     negative           0.843814   sadness       0.843814   \n",
       "2        1  neutral     negative           0.344749   sadness       0.344749   \n",
       "3        1  sadness     negative           0.107874   neutral       0.200429   \n",
       "4        1  neutral    ambiguous           0.339241  surprise       0.339241   \n",
       "\n",
       "          Go   GoScore  \n",
       "0  curiosity  0.330824  \n",
       "1    sadness  0.843814  \n",
       "2    sadness  0.344749  \n",
       "3    neutral  0.200429  \n",
       "4  curiosity  0.585612  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Go_Sentiment']=go_sentiment_emotions\n",
    "df['Go_SentimentScore']=go_sentiment_scores\n",
    "df['Go_Ekman']=go_ekman_emotions\n",
    "df['Go_EkmanScore']=go_ekman_scores\n",
    "df['Go']=go_emotions\n",
    "df['GoScore']=go_scores\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Evaluation of the human response labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 10\n",
      "['sadness', 'neutral', 'neutral', 'neutral', 'sadness', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SYSTEM LABELS TO THE HUMAN RESPONSES\n",
    "human_response_prediction_labels = util.remove_eliza_labels(df, go_ekman_emotions)\n",
    "print(len(go_ekman_emotions), len(human_response_prediction_labels))\n",
    "print(human_response_prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Apply the BoW classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Loading the BoW SVM classifier from MELD and TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO BUILD THE BOW SVM CLASSIFIER FROM MELD AND WASSA TWEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Applying and the classifier to the human part of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES TO CODE TO APPLY HERE COMES THE CODE TO APPLY THE CLASSIFIER TO THE UTTERANCES AND GENERATE THE CLASSIFICATION REPORT AND THE CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE OUTPUT TO THE PANDAS DATA FRAME AS WAS DONE FOR THE GO EMOTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Evaluation of the human response labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SYSTEM LABELS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. [2 BONUS POINT] Sentiment classification and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP EKMAN TO SENTIMENT\n",
    "sentiment_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO MAP THE EKMAN TEST LABELS TO SENTIMENT TEST LABEL\n",
    "\n",
    "def ekman_to_sentiment (sentiment_map, test_labels):\n",
    "    human_sentiment_test_labels = []\n",
    "    return human_sentiment_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(human_test_labels)\n",
    "human_sentiment_test_labels = ekman_to_sentiment(sentiment_map, human_test_labels)\n",
    "print(human_sentiment_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Applying VADER for sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO APPLY VADER TO THE UTTERANCES AND ADD THE OUTPUT TO THE PANDAS DATAFRAME\n",
    "vader_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE VADER SENTIMENT TO THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SYSTEM LABELS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Evaluating the GO_emotion sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE SENTIMENT LABELS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE FOR THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Evaluating the BoW-SVM emotions mapped to sentiment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO MAP THE BOW EKMAN CODE TO SENTIMENT VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE BoW-SVM sentiment to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE PREDICTIONS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Training Bow-SVM with sentiment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A SEPARATE NOTEBOOK lab5.meld-tweet-bow-svm-sentiment-classifier.ipynb TO TRAIN A BOW SVM CLASSIFIER FOR SENTIMENT FROM MELD AND WASSA-TWEETS\n",
    "# SAVE THE CLASSIFIER TO DISK AND LOAD IT HERE\n",
    "\n",
    "# HERE COMES THE CODE TO LOAD A BOW SVM CLASSIFIER FOR SENTIMENT FROM MELD AND WASSA-TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO CLASSIFY THE CONVERSATION WITH SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ADD THE SENTIMENT TO THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REDUCE THE PREDICTIONS TO THE HUMAN RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO TO GENERATE THE CLASSIFICATION REPORT AND THE CONFUSION MATRIX FOR SENTIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving the dataframe will all the predictions to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE FINAL PANDAS FRAME TO A CSV FILE FOR YOUR SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
